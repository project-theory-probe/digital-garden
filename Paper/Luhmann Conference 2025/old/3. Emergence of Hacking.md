##  3. The Emergence of Hacking: Practice Before Programme

  

**Purpose:** Trace how hacking emerged as an operational logic.

**Content:**

- Historical context: early labs (MIT, UNIX), hobbyist communities.
    
- “Hacking” as recursive engagement, not identity or ethos.
    
- Emergence of working / not working distinction as communicative filter.
    
- Note: Don’t romanticize hackers; show recursive stabilization via shared material operations.


## **3. The Emergence of Hacking as a Communicative System**

In this section, we develop the central argument of the paper: that hacking constitutes a communicative system in the Luhmannian sense. We treat hacking not as a subculture, a technical activity, or a moral stance, but as a **distinct mode of social communication** that recursively reproduces itself via the distinction between _working / not working_. This distinction is neither symbolic (like legal/illegal or true/false) nor moral (good/bad), but **materially executable**. It functions through infrastructural enforcement, testing regimes, and recursive validation loops within software environments. By tracing the dynamics of how hacking maintains closure, establishes boundaries, and evolves communication structures, we demonstrate its coherence as a self-referential system.

### **3.1 From Coordination to Recursion: When Practice Becomes a System**

Most descriptions of hacking focus on coordination—how distributed actors align contributions, share knowledge, and resolve technical problems. But coordination alone does not make a system. What distinguishes a communicative system is the **recursion of communication**: the fact that each communication only makes sense with reference to previous communications within the system.

In hacking, this recursion is evident in **commits, forks, issues, and merges**. A contribution is not simply added—it is reviewed, compared, tested, and sometimes rejected. The validity of a new communication depends on its compatibility with prior communications. Even disagreements (e.g. over architecture, tooling, or feature scope) are carried out in terms of _what works_, _what breaks_, or _what integrates cleanly_. These are not neutral observations but **operations within the system’s code**. The decision to merge or reject a contribution reproduces the distinction that structures the system: it works / it doesn’t.

This recursive validation creates the condition for closure. Contributions from outside the system (e.g. a well-written design proposal from a non-coder) are often ignored—not because they lack value, but because they are **non-executable**. They do not participate in the system’s communication unless translated into code, which then must pass the recursive test. This **filtering mechanism** stabilizes the boundary of the system.

### **3.2 Infrastructure as Grammar: The GitHub Effect**

If language structures what can be said in speech, then **infrastructure structures what can be communicated in code**. Platforms like GitHub provide not just a medium but a **grammar of participation**. Issues must follow templates. Code is discussed in pull requests. Changes are expressed in diffs. Decisions are often recorded in commit messages or merge logs.

This grammar is neither entirely formal nor entirely free—it is **socio-technical**. It embeds expectations about how one communicates, how consensus is reached, and how decisions are justified. Over time, these expectations become institutionalized in project guidelines, CONTRIBUTING.md files, and CI/CD pipelines. Newcomers must learn not only the syntax of the language (e.g., Python, C++) but the **syntax of contribution**—the socially sanctioned way of being heard.

This tightly coupled infrastructure performs what Luhmann calls **form selection**: it limits the possibilities of communication by channeling them into routinized patterns. Infrastructure thus stabilizes hacking’s operational closure, while allowing **variation, complexity, and scale**.

### **3.3 The Code That Codes: Binary as Autopoietic Distinction**

At the core of hacking as a communicative system lies the distinction between **working / not working**. This is not a metaphor—it is literally instantiated in build logs, test reports, and deployment outcomes. If something doesn’t compile, doesn’t run, or causes a regression, it is rejected. This binary distinction, enforced through tooling and shared norms, constitutes hacking’s **autopoietic code**.

  

The insight here is subtle but significant: **code itself becomes the code of the system**. Not only does code (as source text) carry information, it also performs the distinction. A failing test is a negative communication. A passing merge is a positive one. This recursive loop—where code both structures and is structured by communication—mirrors the kind of autopoiesis Luhmann describes in legal or economic systems, but without symbolic abstraction. The difference is material and executable.

  

Moreover, this code is **universally testable**. Unlike law or politics, where interpretation depends on culture or precedent, hacking’s code can be validated across contexts: it runs or it doesn’t. This universality gives hacking systems extraordinary **scalability**. A project like the Linux kernel or the Python interpreter coordinates thousands of contributors worldwide using nothing more than this distinction, recursively maintained.

  

### **3.4 Emergence Through Irritation: Coupling Without Assimilation**

  

Like other social systems, hacking does not exist in isolation. It is **structurally coupled** with science (via research code and reproducibility), with law (via open-source licenses), and with the economy (via platform infrastructures and funding). But these couplings do not compromise hacking’s closure. Instead, they are **processed as irritations**—inputs that are **re-coded** in the system’s own terms.

  

For example, when a new regulatory constraint requires encryption, hackers respond by writing encryption modules—not by debating the law. The law enters as a **technical requirement**. Similarly, when funders demand a demonstration of social impact, hackers may implement a dashboard, not a policy report. This re-coding preserves the autonomy of the system.

  

This also explains why **“outside” critiques** often fail to influence hacking practices. Criticism from gender studies, labor ethics, or environmental perspectives rarely alters core development practices unless translated into _what works_. To enter the system, an intervention must become an executable improvement. Thus, hacking’s boundary is not ideological but **ontological**: it is determined by the operational capacity to execute.

  

### **3.5 Reflexivity Without Semantics**

  

Many observers note the **reflexive nature of hacking**. Developers constantly improve their tools, build custom workflows, and automate their own processes. However, this reflexivity is not semantic (i.e., based on meaning or deliberation) but **operational**. The system reflects on itself by improving its capacity to distinguish working from not working—by shortening feedback loops, tightening build times, and enhancing test coverage.

  

In Luhmannian terms, hacking achieves a high degree of **second-order observation**, but without relying on language. A test suite “observes” changes. A linter enforces style. A CI bot blocks regressions. These actors form a **distributed reflexive apparatus**, enabling the system to observe and steer its own communication dynamics. The result is a system that evolves without needing to agree, understand, or represent itself symbolically.

  

### **3.6 When Hacking Becomes Organization**

  

Although hacking often emerges informally, many systems of hacking crystallize into **organizational forms**—project-based organizations, open-source foundations, or platform collectives. Luhmann distinguishes between interaction systems, organization systems, and society. Hacking seems to oscillate between interaction (spontaneous collaboration), organization (GitHub orgs, funding structures), and systemic closure.

  

At a certain point, hacking practices **sediment into roles, routines, and decision premises**. Maintainers begin to coordinate release cycles, create escalation protocols, and enforce contribution guidelines. These structures introduce **internal differentiation**, allowing the system to manage complexity. But they also raise the risk of bureaucratization. The system must balance agility with stability.

  

One solution is **modularization**: splitting the codebase into smaller, loosely coupled components (e.g., packages, modules, microservices). This mirrors the **functional differentiation** in Luhmann’s society. Each module enacts its own closure but remains structurally coupled to the rest of the system. In this way, the hacking system retains coherence without centralization.